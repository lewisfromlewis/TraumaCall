---
title: "Mitch"
author: "Lewis"
date: "13 July 2017"
output: github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

***Trauma Call in Darwin***

*Team Activation Criteria as a predictor of severe trauma; an analysis of the sensitivity and specificity of Royal Darwin Hospital's Trauma Team Callout Criteria.*

**Background**
Studies have shown that patients who have suffered severe trauma have improved outcomes when a multidisciplinary team and attendant resources ("Trauma Team") are mobilised from other tasks on patient arrival to the Emergency Department (ED) 1,2.  In seeking to maximise the benefit of hospital behaviour at the population level, the benefit to severely injured trauma patients is balanced against the effect of removing resources from other areas.  This balance is unlikely to be the same in every trauma centre.  For example, in a hospital with a higher proportion of severely injured patients who arrive in the early phase of trauma, plus both a low *rate* and a constant and low illness *severity* of patients presenting with non traumatic illness, the prior probability of severe trauma that is considered by the person performing triage is high, and the impact of Trauma Team callouts on service for other patients is low, easily predicted and easily mitigated.  This logic underlies the recommendations of many mature health systems for a single trauma centre covering a primary population of 2.5 million (refs?).

Trauma team composition is not closely specified at a national or international level and therefore differs between institutions.  Criteria for trauma team activation also differ mildly between institutions (refs?), as do the characteristics of the patients who arrive at the hospital with trauma and are screened for trauma team activation. The literature also presents a divergent set of clinical and administrative outcomes. The rules by which the Trauma Team is activated have been evaluated by determining their accuracy in the diagnosis of "Severe Trauma" (table / box). Some studies find that mechanism of injury criteria have low accuracy in predicting severe injury 3-5.

Our institution, Royal Darwin Hospital (RDH), is a remote hospital covering a large geographical area with a small population (ref).  There is a high incidence of severe trauma but long retrieval times are common
# (ref from Kath's work; if influential we could add a column of "injury time" and do a quick dirty analysis of that)
and there is a high population burden of non traumatic illness which is both seasonally varying and unpredictably varying (ref).  A dedicated Trauma Service reviews presentations twice daily to identify patients who may have trauma as a reason for admission, maintains a register of current and previous trauma patients and coordinates ongoing care of trauma patients using a nurse led model with close consultant input and 24-hour access to a senior surgical trainee designated as a Trauma Fellow.  Trauma patients admitted to ICU are additionally recorded on a binational registry of all ICU patients. 

The "Trauma Team Callout Criteria" (TTCC) at Royal Darwin Hospital (RDH) is a list of conditions based on pre hospital mechanism of injury and clinical observations on arrival at hospital.  If any one or more of the TTCC are present then a response is activated which is single step and essentially hospital wide (fig1).  A second, lower level of response is initiated on meeting less stringent criteria (fig2).  Our aim, using standard definitions from the literature, was to evaluate the performance of the TTCC, including estimation of the contribution that individual criteria make to the prediction of Severe Trauma in the unique cohort of patients whom we serve.
# I'm more convinced that the Kohn paper didn't use appropriate statistical methodology.  I'll check with even worse regression nerds than I am.  The problems are about the probability of measuring one thing if another thing is present, and then constructing a ROC curve as if the number of positive criteria that are needed for an activation can be altered, when they can't.

```{r}
library(tidyverse)
library(readxl)
library(car)
library(lmtest)
## Next line is run once then replaced with the .csv file in the repo,as the subsequent line: 
## traumata <- read_xlsx("TraumadataV48.xlsx", sheet = 1, n_max = 784)

## The following lines ensure that the predictor criteria are recorded as class = logical in the dataset.
traumata <- read.csv("traumata.csv", stringsAsFactors = F) %>%
  select(1:80)
traumata[traumata=="no"] <- FALSE
traumata[traumata=="No"] <- FALSE
traumata[traumata=="yes"] <- TRUE
traumata[traumata=="Yes"] <- TRUE
write_csv(traumata, "traumata2.csv")
traumata <- read_csv("traumata2.csv")
```
## Methods
**Population**
A list of all patients presenting to RDH ED in the calendar year of 2015 formed the sample frame.  By linkage with the Trauma Registry, ICU Registry, administrative data on mortality and Operating Theatre records we identified 428 patients who had activated a Trauma Call, out of 1712 trauma patients presenting to the Emergency Department and screened using the TTCC.  A further 29 patients were confirmed as Severe Trauma but did not meet the TTCC, of whom 14 also did not meet the second tier criteria (CONSORT table). One decision we faced in this evaluation was the choice of the denominator population.  The diagnostic contingency table (table) will generate higher values for negative predictive value and specificity as the proportion of patients screened in addition to those with severe trauma.

## Results
**Population**
The severity of the ICU cohort for that year is indicated by the median Risk of Death based on the ANZICS APACHEIII score is given below.  The various risk functions give varying risks of death as summarised below, and the standardised mortality ratio across the year is from 0.42 to 0.53 (0.53 using APACHEIII).

```{r}
## Set the scene.
## Next line is run once then replaced with the .csv file in the repo
## Backgroundrate <- read_excel("./Cameron M/DeidentNonop2015.xlsx", sheet = 1)
Backgroundrate <- read_csv('Backgroundrate.csv')
deathtable <- table(Backgroundrate$ICUVitalStatus)
deathrate <- (deathtable[2]/deathtable[1])
deathpredictions <- Backgroundrate[,c(31, 33, 37)]
summary(deathpredictions)
predicteddeaths <- sapply(deathpredictions, sum, na.rm=T)
deathprobabilities <- sapply(deathpredictions, sum, na.rm=T)/dim(deathpredictions)[1]
SMR <- deathrate/deathprobabilities
print(SMR)
```
Major Trauma occurred in 31.5% of those with trauma call criteria, but still seen in 8.1% of those without trauma call criteria.  This is a very influential odds ratio of 5.20 (p value 2.2E-16).
```{r}
table(traumata$Meets_TCC, traumata$Major_Trauma)

TCCpredictsmajor <- glm(traumata$Major_Trauma ~ traumata$Meets_TCC, family="binomial")
anova(TCCpredictsmajor, test="Chisq")

```

Trauma call criteria were more often seen in those who died, odds ratio 4.09, p=0.004 by Chi squared.  For information, the background odds of death for those without a trauma call was 0.01 hence odds of death in those with a trauma call were still only 0.05.
```{r}
table(traumata$Meets_TCC, traumata$Hospital_vital_status)
TCCpredictsdeath <- glm(traumata$Hospital_vital_status=='Dead' ~ traumata$Meets_TCC, family = "binomial")
anova(TCCpredictsdeath, test="Chisq")
```
**Contribution of Criteria**
Examining the informational contribution of trauma call criteria using multivariable logistic regression.  Each component of the trauma call criteria is added sequentially to a multivariable model unless the data are sparse for one of the predictors: because the chi squared test is to be used this means any comparison with a cell count less than 5.  Logistic regression is one of the family of general linear models, which use the value of parameters to predict a response, assuming that the relationship across the values of the parameter holds true.  In each linear model there's a link function, so for a simple linear model it's the identity function, for logistic regression it's the logit function; and there's an assumption about an error structure for the data, in this case I've chosen binomial. So the model produces a set of coefficients, which in this case are the **log odds ratio** for Major_Trauma with each of the predictors, "all else being equal".  So the odds ratio is their exponent to the base e.


```{r}
## Quick glance at the cell size for comparisons, make a table, transpose the rows and columns, read off all where cell counts are 5 or fewer
cellcounts <- 
  sapply(traumata[,c(9, 11, 22:37, 39:69)], table) %>%
  tbl_df() %>%
  t()
cellcounts

## Subset of all columns with non-empty cells
allbutempty <- names(traumata)[c(8, 9, 11, 22:30, 32:33, 35:37, 39:69)]

## Subset of all columns with cell counts more than 5
notsparsedata <- names(traumata)[c(8, 9, 11, 22:24, 26, 28, 29, 32, 37, 39:41, 45:48, 50, 51, 55:58, 59:66, 68, 69)]

## Subset of all columns with cell counts more than 5, using most complete data source and last observation carried onwards
bestdata <- names(traumata)[c(8, 9, 22:24, 26, 28, 29, 32, 37, 39:41, 46, 48, 50, 51, 56, 58, 59:61, 63:66, 68, 69)]

## The most "subjective" criteria are judged to be "significant injury to >2 body areas (69: Significant_multiple_injury)", "respiratory distress (60: Resp_distress)" and "severe facial injury (41: Facial_injury)" and were removed from bestdata for the "less subjective" subset of columns
lesssubjectivedata <- names(traumata)[c(8, 9, 22:24, 26, 28, 29, 32, 37, 39:40, 46, 48, 50, 51, 56, 58, 59, 61, 63:66, 68)]

## Data with close similarity by MeSH heading are grouped, and new predictors using Boolean OR are produced.
grouped1data <- names(traumata)[c(8, 9, 22:24, 26, 28, 29, 32, 37, 39:40, 46, 48, 50, 51, 56, 58, 59, 61, 63:66, 68)]
```
```{r}
# This is a doozy.  The correlation matrix of each predictor with each other predictor
apply(traumata[,lesssubjectivedata], 2, cor, traumata[,lesssubjectivedata], use = "pair")

```

## Linear regression models ##
These are the models that are generated from the data above.
```{r}
## Using bestdata
maximalmodel <- glm(formula = Major_Trauma ~ .,
                  family = "binomial", data = traumata[, bestdata])
mmsummary <- summary(maximalmodel)
drop1(maximalmodel, test="LR")
Anova(maximalmodel, test="F")
vif(maximalmodel)

## Using lesssubjectivedata
lesssubjectivemodel <- glm(formula = Major_Trauma ~ .,
                           family = "binomial", data = traumata[, lesssubjectivedata])
#Generate the list of complete cases among the trauma call criteria, redo both models
# traumacompletecrit <- traumata[complete.cases(traumata[,bestdata]),bestdata]
wholemodelcomplete <- glm(formula = Major_Trauma ~ .,
                  family = "binomial",
                  data = traumata[complete.cases(traumata[,bestdata]),bestdata])
wmcsummary <- summary(wholemodelcomplete)



mantelhaen.test(traumata$Multiple_victims, traumata$SaO2_under_90, traumata$Major_Trauma)
mantelhaen.test(traumata$Flail, traumata$SaO2_under_90, traumata$Major_Trauma)
mantelhaen.test(traumata$Major_Trauma, traumata$GCS_under_14, traumata$SaO2_under_90)
mantelhaen.test(traumata$Major_Trauma, traumata$Intubated, traumata$SaO2_under_90)
mantelhaen.test(traumata$Major_Trauma, traumata$Multiple_victims, traumata$SaO2_under_90)

```

The next models are tedious and painful but give some idea of the predictive contribution of parameters alone.  In the first, only the commonest items are kept and result in a likelihood little lower than with the verbose model *in this sample*.  That may not be the case elsewhere, of course; but it is the case with the data we have.  The most important terms in *this* model, with log odds ratios of over 20, are a significant injury to more than one area, having been intubated, having a "flail chest" whatever that's worth and near drowning. In the presence of these, the other odds are less impressive.  Look below at bulkminimisedmodel to see how this is perhaps not as trustworthy as it seems, then check the coefficients of inversemodel, in which all of the significant predictors from wholemodel have been removed.  Agitation, for example, had OR e^(0.32)=1.38, when it's doing more of the heavy lifting that was previously taken by hypoxia or tachypnoea it carries OR e^(1.87)=6.46.

The performance of the models in predicting the outcome "Major_Trauma" is compared using the likelihood ratio test.  The Likelihood is the probability of the data under a hypothesis.  In all of the calculations below that is the null hypothesis that the odds ratio is 1.
There are limitations to these comparisons.  Firstly, every study like this is subject to sampling error even after excluding the sparse data and some of the fitted probabilities are 1 or 0: perfect prediction. These predictors are not used because they're not true.  It's particularly annoying that 240 observations are deleted due to missingness of one or more variable even after dropping the sparse cells.

Secondly, all else is not equal.  People don't have a middling version of CPR, and the contribution of 2 long bone fractures in the presence of CPR is not independent, it's very much less important than in the absence of CPR.  Or more important, who knows?  The point is that all models have limitations imposed by the size of the dataset used in deriving the model.

Thirdly there are some obviously contributory ones that are excluded from the model, such as CPR and capillary refill time.  A further model needs to be built, the "clinical preference model" where we go down the list and get some colleagues to say think are most useful, and which are least useful.  Then we keep the important ones in and drop the rest one by one.

Now with the minimised model a couple of expected things happen: the log likelihood is lower by 22.  This is a big difference.  So the p value is 4x10^-8.  Fair enough, the more elaborate model predicts outcomes more closely. But the Variance Inflation Factor has gone up only very slightly for all the remaining factors because the absolute difference between a likelihood of e^(-184) and a likelihood of e^(-162) is not very much, and there are fewer places for unmeasured variance to hide.  These are good things for a model.
```{r}
#Close off data manipulations and save current databases
write_csv(traumata, paste("traumata", Sys.Date(),".csv", sep = ""))
write_csv(traumacompletecrit, "traumacompletecriteria.csv")
write_csv(Backgroundrate, "Backgroundrate.csv")
```