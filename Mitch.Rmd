---
title: "Mitch"
author: "Lewis"
date: "13 July 2017"
output: github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

**Trauma Team Activation Criteria as a predictor of severe trauma; an analysis of the sensitivity and specificity of Royal Darwin Hospital's Trauma Team Callout Criteria.**

*Project Description*
*Background*
Studies have shown that patients who have suffered severe trauma have improved outcomes when a multidisciplinary team and attendant resources are mobilised from other tasks on patient arrival1,2.  In seeking to maximise the benefit of hospital behaviour at the population level, the benefit to severely injured trauma patients is balanced against the effect of removing resources from other areas.  This balance is unlikely to be the same in every trauma centre

Trauma team composition is not closely specified at a national or international level and therefore differs between institutions.  Criteria for trauma team activation also differ mildly between institutions (refs?), as do the characteristics of the patients who arrive at the hospital with trauma and are screened for trauma team activation.  It is inherent in the service specifications that the greatest population benefit would be seen a hospital with a higher proportion of severely injured patients arriving in the early phase of trauma, plus both a low rate and a constant and low illness severity of patients presenting with non traumatic illness.  This logic underlies the recommendations of many mature health systems for a single trauma centre covering a primary population of 2.5 million (refs?).

Our institution, Royal Darwin Hospital, is a remote hospital covering a large geographical area with a small population (ref).  There is a high incidence of severe trauma but long retrieval times are common (ref from Kath's work; if influential we could add a column of "injury time" and do a quick dirty analysis of that) and there is a high population burden of non traumatic illness which is both seasonally varying and unpredictably varying (ref).  The "Trauma Team Callout Criteria" (TTCC) at Royal Darwin Hospital (RDH) include pre hospital (mechanism of injury) and clinical criteria for activation.  Mechanism of injury criteria have low predictive value for severe injury3-5 and may lead to a high rate of over-triage for RDH's trauma patients.

```{r}
library(tidyverse)
library(lubridate)
library(readxl)
library(car)
library(lmtest)
## Next line is run once then replaced with the .csv file in the repo,as the subsequent line: 
## traumata <- read_xlsx("TraumadataV48.xlsx", sheet = 1, n_max = 784)
traumata <- read_csv("traumata.csv")
```
The severity of the whole cohort for that year is indicated by the median Risk of Death based on the ANZICS APACHEIII score is given below.  The various risk functions give varying risks of death as summarised below, and the standardised mortality ratio across the year is from 0.42 to 0.53 (0.53 using APACHEIII).

```{r}
## Next line is run once then replaced with the .csv file in the repo
## Backgroundrate <- read_excel("./Cameron M/DeidentNonop2015.xlsx", sheet = 1)
Backgroundrate <- read_csv('Backgroundrate.csv')
deathtable <- table(Backgroundrate$ICUVitalStatus)
deathrate <- (deathtable[2]/deathtable[1])
deathpredictions <- Backgroundrate[,c(31, 33, 37)]
summary(deathpredictions)
predicteddeaths <- sapply(deathpredictions, sum, na.rm=T)
deathprobabilities <- sapply(deathpredictions, sum, na.rm=T)/dim(deathpredictions)[1]
SMR <- deathrate/deathprobabilities
print(SMR)
```
Major trauma occurred in 31.5% of those with trauma call criteria, but still seen in 8.1% of those without trauma call criteria.  This is a very influential odds ratio of 5.20 (p value 2.2E-16).
```{r}
table(traumata$`Meets TCC`, traumata$`Major Trauma`)
TCCpredictsmajor <- glm(traumata$`Major Trauma`=='yes' ~ traumata$`Meets TCC`, family="binomial")
anova(TCCpredictsmajor, test="Chisq")
```

Trauma call criteria were more often seen in those who died, odds ratio 4.09, p=0.004 by Chi squared.  For information, the background odds of death for those without a trauma call was 0.01 hence odds of death in those with a trauma call were still only 0.05.
```{r}
table(traumata$`Meets TCC`, traumata$`Discharge Status`)
TCCpredictsdeath <- glm(traumata$`Discharge Status`=='Dead' ~ traumata$`Meets TCC`, family = "binomial")
anova(TCCpredictsdeath, test="Chisq")
```
**Contribution of Criteria**
Examining the informational contribution of trauma call criteria using multivariable logistic regression.  Each component of the trauma call criteria is added sequentially to a multivariable model unless the data are sparse for one of the predictors: because the chi squared test is to be used this means any comparison with a cell count less than 5.  Logistic regression is one of the family of general linear models, which use the value of parameters to predict a response, assuming that the relationship across the values of the parameter holds true.  In each linear model there's a link function, so for a simple linear model it's the identity function, for logistic regression it's the logit function; and there's an assumption about an error structure for the data, in this case I've chosen binomial. So the model produces a set of coefficients, which in this case are the **log odds ratio** for major trauma with each of the predictors, "all else being equal".  So the odds ratio is their exponent to the base e.


```{r}
## Quick glance at the cell size for comparisons:
str(sapply(traumata[,22:62], table))
## Excluded by this method (all but Neuro Def had cell counts 5 or fewer; neuro def was 6 but collinear with motor def): CPR + `Motor Loss` + `Sens Loss` + `Neuro Def` + Cyanosis + `RR<8` + `Amput Limb` + `CR<2s` + `HR<50` + `Inhal Burns` + `Blast Injury` + Drowning + `Crush head` + `Crush neck` + `Pen head` + `Bicycle vs car`

wholemodel <- glm(formula = `Major Trauma`=='yes' ~ `multi?` + 
                    `MVA ejection` + `MVA entrapment` + 
                    `MVA fatality at scene` + 
                    `Ped vs car` + `Pen neck` + 
                    `Pen torso` + `Crush torso` + 
                    `Burns >15%` + `Near Drown` + 
                    `Fall >3m` + `Air Comp` + Intubated + 
                    `Sev fac inj` + 
                    `HR>120` + `SBP<90` + `Pel Unstab` + 
                    `RR>30` + `SaO2<90` + 
                    `Resp distr` + Flail + `GCS ≤13` + Agitated + 
                    Seizure + `Sig Inj ≥2` , 
                  family = "binomial", data = traumata)
wholemodel
drop1(wholemodel, test="Chisq")
anova(wholemodel, test="Chisq")
vif(wholemodel)
## lrtest once further models built
```

The next models are tedious and painful but give some idea of the predictive contribution of parameters alone.  In the first, only the commonest items are kept and result in a likelihood little lower than with the verbose model *in this sample*.  That may not be the case elsewhere, of course; but it is the case with the data we have.  The most important terms in *this* model, with log odds ratios of over 20, are a significant injury to more than one area, having been intubated, having a "flail chest" whatever that's worth and near drowning. In the presence of these, the other odds are less impressive.  Look below at bulkminimisedmodel to see how this is perhaps not as trustworthy as it seems.
```{r}
## Only the commonest items are kept
bulkmodel <- glm(formula = `Major Trauma`=='yes' ~ `multi?` + 
                    `MVA ejection` + `MVA entrapment` + 
                    `MVA fatality at scene` + 
                    `Ped vs car` + `Pen neck` + 
                    `Pen torso` + 
                    `Burns >15%` + `Near Drown` + 
                    `Fall >3m` + `Air Comp` + Intubated + 
                    `Sev fac inj` + 
                    `HR>120` + `SBP<90` + `Pel Unstab` + 
                    `RR>30` + `SaO2<90` + 
                    `Resp distr` + Flail + `GCS ≤13` + Agitated + 
                    Seizure + `Sig Inj ≥2` , 
                  family = "binomial", data = traumata)
bulkmodel
anova(bulkmodel, test="Chisq")
drop1(bulkmodel)
vif(bulkmodel)
lrtest(wholemodel, bulkmodel)
```
The performance of the models in predicting the outcome "Major Trauma" is compared using the likelihood ratio test.  The Likelihood is the probability of the data under a hypothesis.  In all of the calculations below that is the null hypothesis that the odds ratio is 1.
There are limitations to these comparisons.  Firstly, every study like this is subject to sampling error even after excluding the sparse data and some of the fitted probabilities are 1 or 0: perfect prediction. These predictors are not used because they're not true.  It's particularly annoying that 240 observations are deleted due to missingness of one or more variable even after dropping the sparse cells.

Secondly, all else is not equal.  People don't have a middling version of CPR, and the contribution of 2 long bone fractures in the presence of CPR is not independent, it's very much less important than in the absence of CPR.  Or more important, who knows?  The point is that all models have limitations imposed by the size of the dataset used in deriving the model.

Thirdly there are some obviously contributory ones that are excluded from the model, such as CPR and capillary refill time.  A further model needs to be built, the "clinical preference model" where we go down the list and get some colleagues to say think are most useful, and which are least useful.  Then we keep the important ones in and drop the rest one by one.

```{r}
## Remove those with VIF>2:  `Sig Inj ≥2` + `Pel Unstab` + `Sev fac inj` +  Intubated + `Ped vs car`
bulkmodelminimised <- glm(formula = `Major Trauma`=='yes' ~ `multi?` + 
                    `MVA ejection` + `MVA entrapment` + 
                    `MVA fatality at scene` + 
                    `Pen neck` + 
                    `Pen torso` + 
                    `Burns >15%` + `Near Drown` + 
                    `Fall >3m` + `Air Comp` +
                    `HR>120` + `SBP<90` +
                    `RR>30` + `SaO2<90` + 
                    `Resp distr` + Flail + `GCS ≤13` + Agitated + 
                    Seizure, 
                  family = "binomial", data = traumata)
bulkmodelminimised
anova(bulkmodelminimised, test="Chisq")
lrtest(bulkmodel, bulkmodelminimised)
lrtest(wholemodel, bulkmodelminimised)
vif(bulkmodelminimised)
```
Now with the minimised model a couple of expected things happen: the log likelihood is lower by 22.  This is a big difference.  So the p value is 4x10^-8.  Fair enough, the more elaborate model predicts outcomes more closely. But the Variance Inflation Factor has gone up only very slightly for all the remaining factors because the absolute difference between a likelihood of e^(-184) and a likelihood of e^(-162) is not very much, and there are fewer places for unmeasured variance to hide.  These are good things for a model.
```{r}
#Close off data manipulations and save current databases
write_csv(traumata, paste("traumata", "Sys.Date()",".csv"))
write_csv(Backgroundrate, "Backgroundrate.csv")
```