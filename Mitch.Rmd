---
title: "Mitch"
author: "Lewis"
date: "13 July 2017"
output: github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

****Trauma Call in Darwin****

*Team Activation Criteria as a predictor of severe trauma; an analysis of the sensitivity and specificity of Royal Darwin Hospital's Trauma Team Callout Criteria.*

**Background**
RDH is a unique environment.  We aim to describe the association of Trauma Call Criteria with patient centred outcomes in a cohort of patients screened for trauma.  We also describe the prevalence of individual criteria in the population of trauma patients, and estimate the predictive ability of individual criteria for patient centred outcomes.  We discuss the possible implications of simplifying the criteria as if applied to this cohort.

```{r, echo=FALSE}

# I'm more convinced that the Kohn paper didn't use appropriate statistical methodology.  I'll check with even worse regression nerds than I am.  The problems are about the probability of measuring one thing if another thing is present, and then constructing a ROC curve as if the number of positive criteria that are needed for an activation can be altered, when they can't.

library(tidyverse)
library(readxl)
library(car)
library(lmtest)
## Next line is run once then replaced with the .csv file in the repo,as the subsequent line: 
## traumata <- read_xlsx("TraumadataV48.xlsx", sheet = 1, n_max = 784)

## The following lines ensure that the predictor criteria are recorded as class = logical in the dataset.
traumata <- read.csv("traumata.csv", stringsAsFactors = F) %>%
  select(1:80)
traumata[traumata=="no"] <- FALSE
traumata[traumata=="No"] <- FALSE
traumata[traumata=="yes"] <- TRUE
traumata[traumata=="Yes"] <- TRUE
write_csv(traumata, "traumata2.csv")
traumata <- read_csv("traumata2.csv")
file.remove("traumata2.csv")
```

```{r, echo = 8}
## Set the scene.
## Next line is run once then replaced with the .csv file in the repo
## Backgroundrate <- read_excel("./Cameron M/DeidentNonop2015.xlsx", sheet = 1)
Backgroundrate <- read_csv('Backgroundrate.csv')
(deathtable <- table(Backgroundrate$ICUVitalStatus))
deathrate <- (deathtable[2]/deathtable[1])
deathpredictions <- Backgroundrate[,c(31, 33, 37)]
summary(deathpredictions)
predicteddeaths <- sapply(deathpredictions, sum, na.rm=T)
deathprobabilities <- sapply(deathpredictions, sum, na.rm=T)/dim(deathpredictions)[1]
SMR <- deathrate/deathprobabilities
print(SMR)
```
Of patients admitted to ICU that year, 88/815 or 10.8% of patients died, which is well below benchmark mortality as shown by the SMR using various models.  Major Trauma occurred in 31.5% of those with trauma call criteria, but still seen in 8.1% of those without trauma call criteria.  This is a very influential odds ratio of 5.20 (p value <2.2E-16).  When using a larger denominator population who may not have been screened for major trauma the odds ratio is 17.4 (p value <2.2E-16).  This is a slightly trivial result as the odds for severe trauma in patients without trauma is zero, hence the odds ratio for any trauma criterion is infinite when applied to an unselected population.  Henceforth we use the cohort of 784 patients who either had severe trauma or were likely to be screened for severe trauma.
```{r, echo=c(1,3)}
table(traumata$Meets_TCC, traumata$Major_Trauma)
TCCpredictsmajor <- glm(traumata$Major_Trauma ~ traumata$Meets_TCC, family="binomial")
#"Intention to treat" style
TCCpredictsITT <- glm(c(traumata$Major_Trauma, rep(FALSE, 1551-784)) ~ c(traumata$Meets_TCC, rep(FALSE, 1551-784)), family="binomial")
anova(TCCpredictsmajor, test="Chisq")
anova(TCCpredictsITT, test = "Chisq")
# These next steps are to make the environment more efficient
TCCpredictsmajor <- summary(TCCpredictsmajor)
TCCpredictsITT <- summary(TCCpredictsITT)
```

Trauma call criteria were more often seen in those who died, odds ratio 4.09, p=0.004 by Chi squared.  For information, the background odds of death for those without a trauma call was 0.01 hence odds of death in those with a trauma call were still only 0.05.
```{r}
table(traumata$Meets_TCC, traumata$Hospital_vital_status)
TCCpredictsdeath <- glm(traumata$Hospital_vital_status=='Dead' ~ traumata$Meets_TCC, family = "binomial")

anova(TCCpredictsdeath, test="Chisq")
```

**Prevalence of criteria in the cohort**


```{r}
## Quick glance at the cell size for comparisons, make a table, transpose the rows and columns, read off all where cell counts are 5 or fewer
cellcounts <- 
  sapply(traumata[,c(9, 11, 22:37, 39:69)], table) %>%
  tbl_df() %>%
  t()
cellcounts

## Subset of all columns with non-empty cells
allbutempty <- names(traumata)[c(8, 9, 11, 22:30, 32:33, 35:37, 39:69)]

## Subset of all columns with cell counts more than 5
notsparsedata <- names(traumata)[c(8, 9, 11, 22:24, 26, 28, 29, 32, 37, 39:41, 45:48, 50, 51, 55:58, 59:66, 68, 69)]

## Subset of all columns with cell counts more than 5, using most complete data source and last observation carried onwards
bestdata <- names(traumata)[c(8, 9, 22:24, 26, 28, 29, 32, 37, 39:41, 46, 48, 50, 51, 56, 58, 59:61, 63:66, 68, 69)]

## The most "subjective" criteria are judged to be "significant injury to >2 body areas (69: Significant_multiple_injury)", "respiratory distress (60: Resp_distress)" and "severe facial injury (41: Facial_injury)" and were removed from bestdata for the "less subjective" subset of columns
lesssubjectivedata <- names(traumata)[c(8, 9, 22:24, 26, 28, 29, 32, 37, 39:40, 46, 48, 50, 51, 56, 58, 59, 61, 63:66, 68)]

## Data with close similarity by MeSH heading are grouped, and new predictors using Boolean "OR" are produced then added to the end of the traumata dataset.  This is the first collapse and so is Collapse 1 or CO1
traumata1 <- traumata %>%
  mutate(CO1_Unequal_Mass = Ped_v_car | Bicycle_v_car,
         CO1_Military = Burns_over_15percent | Blast_Injury,
         CO1_Scene_Complications = CPR | Amputated_Limb | MVAejection | MVAentrapment | Multiple_fractures,
         CO1_Scene_Epidemiology = Near_Drown| Drowning | Fall_morethan_3m | Multiple_victims | MVAfatality_at_scene,
         CO1_Penetrating_midline = Pen_head | Pen_neck | Pen_torso,
         CO1_Crushing_midline = Facial_injury | Crush_head | Crush_neck | Crush_torso | Pel_Unstab | Flail,
         CO1_Airway_criteria = Airway_compromise | Airway_burns | Intubated,
         CO1_Breathing_criteria = MD_RR_under_8 | MD_RR_over_30 | MD_SaO2_under_90 | Cyanosis | Resp_distress,
         CO1_Circ_criteria = CR_over_2s | MD_HR_under_50 | MD_HR_over_120 | MD_SBP_under_90,
         CO1_Neuro_criteria = MD_GCSunder14 | Neuro_Deficit | Seizure | Motor_Loss | Sens_Loss | Agitated)

# This is the second collapse, CO2 and selects criteria from bestdata before collapse
traumata2 <- traumata %>%
  mutate(CO2_Scene_Complications = MVAejection | MVAentrapment | Multiple_fractures,
         CO2_Scene_Epidemiology = Fall_morethan_3m | Multiple_victims | MVAfatality_at_scene,
         CO2_Penetrating_midline = Pen_neck | Pen_torso,
         CO2_Crushing_midline = Facial_injury | Crush_neck | Crush_torso | Pel_Unstab | Flail,
         
         CO2_Breathing_criteria = MD_RR_over_30 | MD_SaO2_under_90 | Cyanosis | Resp_distress,
         CO2_Circ_criteria = MD_HR_over_120 | MD_SBP_under_90,
         CO2_Neuro_criteria = MD_GCSunder14 | Neuro_Deficit | Seizure | Sens_Loss)
#This is the third collapse.  All possible indicators go into CO3; then The Final Collapse is based on bestdata again, simply collapsed and called The Omega.
traumata3 <- traumata %>% 
  mutate(CO3_mechanism = Ped_v_car | Bicycle_v_car | Blast_Injury | MVAejection |
           MVAentrapment | Near_Drown | Fall_morethan_3m | Multiple_victims |
           MVAfatality_at_scene | Airway_burns,
         CO3_injury = Amputated_Limb | Multiple_fractures | Burns_over_15percent |
           Pen_head | Pen_neck | Pen_torso | Crush_head | Crush_neck | Crush_torso |
           Pel_Unstab | Facial_injury | Intubated,
         CO3_physiology = CPR | Flail | Airway_compromise | MD_RR_over_30 |
           MD_SaO2_under_90 | Cyanosis | Resp_distress | MD_RR_under_8 | CR_over_2s |
           MD_HR_under_50 | MD_HR_over_120 | MD_SBP_under_90 |
           MD_GCSunder14 | Neuro_Deficit | Seizure | Motor_Loss | Sens_Loss | Agitated)

```
```{r}
# This is a doozy.  The correlation matrix of each predictor with each other predictor
predictor_correlations <- apply(traumata[,lesssubjectivedata], 2, cor, traumata[,lesssubjectivedata], use = "pair")

mantelhaen.test(traumata$Multiple_victims, traumata$SaO2_under_90, traumata$Major_Trauma)
mantelhaen.test(traumata$Flail, traumata$SaO2_under_90, traumata$Major_Trauma)
mantelhaen.test(traumata$Major_Trauma, traumata$GCS_under_14, traumata$SaO2_under_90)
mantelhaen.test(traumata$Major_Trauma, traumata$Intubated, traumata$SaO2_under_90)
mantelhaen.test(traumata$Major_Trauma, traumata$Multiple_victims, traumata$SaO2_under_90)
```


**Contribution of Criteria: Linear regression models**
Examining the informational contribution of trauma call criteria using multivariable logistic regression.  Each component of the trauma call criteria is added sequentially to a multivariable model unless the data are sparse for one of the predictors: because the chi squared test is to be used this means any comparison with a cell count less than 5.  Logistic regression is one of the family of general linear models, which use the value of parameters to predict a response, assuming that the relationship across the values of the parameter holds true.  In each linear model there's a link function, so for a simple linear model it's the identity function, for logistic regression it's the logit function; and there's an assumption about an error structure for the data, in this case I've chosen binomial. So the model produces a set of coefficients, which in this case are the **log odds ratio** for Major_Trauma with each of the predictors, "all else being equal".  So the odds ratio is their exponent to the base e.

These are the models that are generated from the data above.
```{r}
## Using bestdata
maximalmodel <- glm(formula = Major_Trauma ~ .,
                  family = "binomial", data = traumata[, bestdata])
mmsummary <- summary(maximalmodel)
drop1(maximalmodel, test="LR")
Anova(maximalmodel, test="F")
vif(maximalmodel)

## Using lesssubjectivedata
lesssubjectivemodel <- glm(formula = Major_Trauma ~ .,
                           family = "binomial", data = traumata[, lesssubjectivedata])
lssummary <- summary(lesssubjectivemodel)
#Generate the list of complete cases among the trauma call criteria, redo both models
# traumacompletecrit <- traumata[complete.cases(traumata[,bestdata]),bestdata]
wholemodelcomplete <- glm(formula = Major_Trauma ~ .,
                  family = "binomial",
                  data = traumata[complete.cases(traumata[,bestdata]),bestdata])
wmcsummary <- summary(wholemodelcomplete)

#Using the collapsed criteria in models
collapsedmodel1 <- glm(formula = Major_Trauma ~ CO1_Unequal_Mass + CO1_Military +
                        CO1_Scene_Complications + CO1_Scene_Epidemiology + 
                        CO1_Crushing_midline + CO1_Penetrating_midline + 
                        CO1_Airway_criteria + CO1_Breathing_criteria + CO1_Circ_criteria +
                        CO1_Neuro_criteria + Significant_multiple_injury,
                      family = "binomial", data = traumata)
cm1summary <- summary(collapsedmodel1)

collapsedmodel2 <- glm(formula = Major_Trauma ~ Ped_v_car +
                        CO2_Scene_Complications + CO2_Scene_Epidemiology + 
                        CO1_Crushing_midline + CO1_Penetrating_midline + 
                        Intubated + CO1_Breathing_criteria + CO1_Circ_criteria +
                        CO2_Neuro_criteria + Significant_multiple_injury,
                      family = "binomial", data = traumata)
cm2summary <- summary(collapsedmodel2)

collapsedmodel3 <- glm(formula = Major_Trauma ~ CO3_mechanism + CO3_injury + CO3_physiology,
                      family = "binomial", data = traumata)
cm3summary <- summary(collapsedmodel3)
# The above models were about the prediction of "Major Trauma".  To round off, a couple of models about prediction of ISS >15.

collapsedISSmodel2 <- glm(formula = ISS_over_15 ~ Ped_v_car +
                        CO2_Scene_Complications + CO2_Scene_Epidemiology + 
                        CO1_Crushing_midline + CO1_Penetrating_midline + 
                        Intubated + CO1_Breathing_criteria + CO1_Circ_criteria +
                        CO2_Neuro_criteria + Significant_multiple_injury,
                      family = "binomial", data = traumata)
ISS2summary <- summary(collapsedISSmodel2)

```
The collapsed criteria have an unquenchable influence of their most important members as seen in the model containing all criteria.  Looks like there's no way to cut it that doesn't retain their dominance. One curious feature is that including CPR in "scene complications" doesn't alter either one's significance or influence.  Another curious thing is that Intubated doesn't achieve statistical significance in this model, despite being mathematically coupled with the outcome!! What the hell do you have to do to gerrymander a predictor in this cohort?

The next models are tedious and painful but give some idea of the predictive contribution of parameters alone.  In the first, only the commonest items are kept and result in a likelihood little lower than with the verbose model *in this sample*.  That may not be the case elsewhere, of course; but it is the case with the data we have.  The most important terms in *this* model, with log odds ratios of over 20, are a significant injury to more than one area, having been intubated, having a "flail chest" whatever that's worth and near drowning. In the presence of these, the other odds are less impressive.  Look below at bulkminimisedmodel to see how this is perhaps not as trustworthy as it seems, then check the coefficients of inversemodel, in which all of the significant predictors from wholemodel have been removed.  Agitation, for example, had OR e^(0.32)=1.38, when it's doing more of the heavy lifting that was previously taken by hypoxia or tachypnoea it carries OR e^(1.87)=6.46.

The performance of the models in predicting the outcome "Major_Trauma" is compared using the likelihood ratio test.  The Likelihood is the probability of the data under a hypothesis.  In all of the calculations below that is the null hypothesis that the odds ratio is 1.
There are limitations to these comparisons.  Firstly, every study like this is subject to sampling error even after excluding the sparse data and some of the fitted probabilities are 1 or 0: perfect prediction. These predictors are not used because they're not true.  It's particularly annoying that 240 observations are deleted due to missingness of one or more variable even after dropping the sparse cells.

Secondly, all else is not equal.  People don't have a middling version of CPR, and the contribution of 2 long bone fractures in the presence of CPR is not independent, it's very much less important than in the absence of CPR.  Or more important, who knows?  The point is that all models have limitations imposed by the size of the dataset used in deriving the model.

Thirdly there are some obviously contributory ones that are excluded from the model, such as CPR and capillary refill time.  A further model needs to be built, the "clinical preference model" where we go down the list and get some colleagues to say think are most useful, and which are least useful.  Then we keep the important ones in and drop the rest one by one.

Now with the minimised model a couple of expected things happen: the log likelihood is lower by 22.  This is a big difference.  So the p value is 4x10^-8.  Fair enough, the more elaborate model predicts outcomes more closely. But the Variance Inflation Factor has gone up only very slightly for all the remaining factors because the absolute difference between a likelihood of e^(-184) and a likelihood of e^(-162) is not very much, and there are fewer places for unmeasured variance to hide.  These are good things for a model.
```{r}
#Close off data manipulations and save current databases
write_csv(traumata, paste("traumata", Sys.Date(),".csv", sep = ""))
write_csv(Backgroundrate, "Backgroundrate.csv")
```